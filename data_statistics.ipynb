{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/melinaplakidis/Documents/Uni/HA-DeepLearning/data\n"
     ]
    }
   ],
   "source": [
    "# Set paths\n",
    "WORKING_DIR = os.getcwd()\n",
    "DATA_DIR = \"data\"\n",
    "full_path = os.path.join(WORKING_DIR, DATA_DIR)\n",
    "print(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in train and test set files (comment out the ones that are not needed)\n",
    "multi_train = pd.read_csv(os.path.join(full_path,\"multi_train_v1_dataset.csv\"))\n",
    "multi_test = pd.read_csv(os.path.join(full_path,\"multi_test_v1_dataset.csv\"))\n",
    "binary_train = pd.read_csv(os.path.join(full_path, \"binary_train_v1_dataset.csv\"))\n",
    "binary_test = pd.read_csv(os.path.join(full_path,\"binary_test_v1_dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label mapping (comment out the ones that are not needed)\n",
    "labels_to_sa_ids = {'ASSERTIVE': 0, 'COMOTH': 1, 'DIRECTIVE': 2, 'EXPRESSIVE': 3, 'UNSURE': 4}\n",
    "labels_to_binary_ids = {'offensive': 0, 'other': 1}\n",
    "labels_to_hs_ids = {'abuse': 0, 'explicit': 1, 'implicit': 2, 'insult': 3, 'other': 4, 'profanity': 5}\n",
    "ids_to_sa_labels = {0: 'ASSERTIVE', 1: 'COMOTH', 2: 'DIRECTIVE', 3: 'EXPRESSIVE', 4: 'UNSURE'}\n",
    "ids_to_hs_labels = {0: 'abuse', 1: 'explicit', 2: 'implicit', 3: 'insult', 4: 'other', 5: 'profanity'}\n",
    "ids_to_binary_labels = {0: 'offensive', 1: 'other'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to get frequencies\n",
    "\n",
    "# Count hate speech labels\n",
    "def count_hs_labels(df, binary=True): # if fine-grained labels are evaluated, set binary=False\n",
    "    label_counts = df[\"labels\"].value_counts()\n",
    "    count_dict = {}\n",
    "    for i  in range(0, len(label_counts)):\n",
    "        if binary:\n",
    "            count_dict[ids_to_binary_labels[i]] = label_counts[i]\n",
    "        else:\n",
    "            count_dict[ids_to_hs_labels[i]] = label_counts[i]\n",
    "    return count_dict\n",
    "\n",
    "# Count speech act labels\n",
    "def count_sa_labels(df): \n",
    "    texts = df[\"texts\"].tolist()\n",
    "    count_dict = {}\n",
    "    for text in texts:\n",
    "        splitted = text.split(\"[SEP]\")\n",
    "        for i in range(1,len(splitted)):\n",
    "            if splitted[i] in labels_to_sa_ids:\n",
    "                if splitted[i] in count_dict:\n",
    "                    count_dict[splitted[i]] += 1\n",
    "                else:\n",
    "                    count_dict[splitted[i]] = 1\n",
    "            else:\n",
    "                continue\n",
    "    ordered = collections.OrderedDict(sorted(count_dict.items()))\n",
    "    return ordered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to create final tables\n",
    "\n",
    "# Create two dataframes for hate speech and speech act labels\n",
    "def create_table(train, test, binary=True): # if fine-grained labels are evaluated, set binary=False\n",
    "    if binary:\n",
    "        hs_df = pd.DataFrame({\"Offensiveness\": list(count_hs_labels(test).keys()), \"Test\":list(count_hs_labels(test).values()), \"Train\": list(count_hs_labels(train).values())})\n",
    "        sa_df = pd.DataFrame({\"Speech Acts\": list(labels_to_sa_ids.keys()), \"Test\":list(count_sa_labels(test).values()), \"Train\": list(count_sa_labels(train).values())}) \n",
    "    else:\n",
    "        hs_df = pd.DataFrame({\"Offensiveness\": list(count_hs_labels(test, binary=False).keys()), \"Test\":list(count_hs_labels(test, binary=False).values()), \"Train\": list(count_hs_labels(train, binary=False).values())})\n",
    "        sa_df = pd.DataFrame({\"Speech Acts\": list(labels_to_sa_ids.keys()), \"Test\":list(count_sa_labels(test).values()), \"Train\": list(count_sa_labels(train).values())}) \n",
    "    return hs_df, sa_df\n",
    "\n",
    "# Add relative frequencies to dataframe\n",
    "def add_relative_frequencies(df):\n",
    "    rel_train, rel_test = [], []\n",
    "    for train, test in zip(df[\"Train\"], df[\"Test\"]):\n",
    "        total = train + test\n",
    "        rel_train.append((train/total)*100)\n",
    "        rel_test.append((test/total)*100)\n",
    "    df[\"Rel_Test\"] = rel_test\n",
    "    df[\"Rel_Train\"] = rel_train\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "Offensiveness &  Test &  Train &  Rel\\_Test &  Rel\\_Train \\\\\n",
      "\\midrule\n",
      "        abuse &    20 &     80 &      20.0 &       80.0 \\\\\n",
      "     explicit &    20 &     80 &      20.0 &       80.0 \\\\\n",
      "     implicit &    20 &     80 &      20.0 &       80.0 \\\\\n",
      "       insult &    20 &     80 &      20.0 &       80.0 \\\\\n",
      "        other &    20 &     80 &      20.0 &       80.0 \\\\\n",
      "    profanity &    20 &     80 &      20.0 &       80.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "Speech Acts &  Test &  Train &  Rel\\_Test &  Rel\\_Train \\\\\n",
      "\\midrule\n",
      "  ASSERTIVE &   144 &    520 & 21.686747 &  78.313253 \\\\\n",
      "     COMOTH &    17 &     71 & 19.318182 &  80.681818 \\\\\n",
      "  DIRECTIVE &   123 &    507 & 19.523810 &  80.476190 \\\\\n",
      " EXPRESSIVE &    82 &    310 & 20.918367 &  79.081633 \\\\\n",
      "     UNSURE &    17 &    133 & 11.333333 &  88.666667 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/4yx64stx14x98pvlwz2br_nr0000gn/T/ipykernel_35109/2766343243.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(hs_df.to_latex(index=False))\n",
      "/var/folders/7k/4yx64stx14x98pvlwz2br_nr0000gn/T/ipykernel_35109/2766343243.py:6: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(sa_df.to_latex(index=False))\n"
     ]
    }
   ],
   "source": [
    "# Create two dataframes to get frequencies of speech act and hate speech labels\n",
    "hs_df, sa_df = create_table(multi_train, multi_test, binary=False)\n",
    "# Add relative frequencies to dataframes\n",
    "hs_df = add_relative_frequencies(hs_df)\n",
    "sa_df = add_relative_frequencies(sa_df)\n",
    "# Print latex tables\n",
    "print(hs_df.to_latex(index=False))\n",
    "print(sa_df.to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-nightly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
