{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/melinaplakidis/Documents/Uni/HA-DeepLearning/data\n"
     ]
    }
   ],
   "source": [
    "# Set paths\n",
    "WORKING_DIR = os.getcwd()\n",
    "DATA_DIR = \"data\"\n",
    "full_path = os.path.join(WORKING_DIR, DATA_DIR)\n",
    "print(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in train and test set files \n",
    "train = pd.read_csv(os.path.join(full_path,\"train_dataset.csv\"))\n",
    "test = pd.read_csv(os.path.join(full_path,\"test_dataset.csv\"))\n",
    "binary_train = pd.read_csv(os.path.join(full_path, \"binary_train_dataset.csv\"))\n",
    "binary_test = pd.read_csv(os.path.join(full_path,\"binary_test_dataset.csv\"))\n",
    "labels_to_sa_ids = {'ASSERTIVE': 0, 'COMOTH': 1, 'DIRECTIVE': 2, 'EXPRESSIVE': 3, 'UNSURE': 4}\n",
    "labels_to_binary_ids = {'offensive': 0, 'other': 1}\n",
    "labels_to_hs_ids = {'abuse': 0, 'explicit': 1, 'implicit': 2, 'insult': 3, 'other': 4, 'profanity': 5}\n",
    "ids_to_sa_labels = {0: 'ASSERTIVE', 1: 'COMOTH', 2: 'DIRECTIVE', 3: 'EXPRESSIVE', 4: 'UNSURE'}\n",
    "ids_to_hs_labels = {0: 'abuse', 1: 'explicit', 2: 'implicit', 3: 'insult', 4: 'other', 5: 'profanity'}\n",
    "ids_to_binary_labels = {0: 'offensive', 1: 'other'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define methods to get frequencies\n",
    "\n",
    "def count_hs_labels(df, binary=True):\n",
    "    label_counts = df[\"labels\"].value_counts()\n",
    "    count_dict = {}\n",
    "    for i  in range(0, len(label_counts)):\n",
    "        if binary:\n",
    "            count_dict[ids_to_binary_labels[i]] = label_counts[i]\n",
    "        else:\n",
    "            count_dict[ids_to_hs_labels[i]] = label_counts[i]\n",
    "    return count_dict\n",
    "\n",
    "def count_sa_labels(df):\n",
    "    texts = df[\"texts\"].tolist()\n",
    "    count_dict = {}\n",
    "    for text in texts:\n",
    "        splitted = text.split(\"[SEP]\")\n",
    "        for i in range(1,len(splitted)):\n",
    "            if splitted[i] in labels_to_sa_ids:\n",
    "                if splitted[i] in count_dict:\n",
    "                    count_dict[splitted[i]] += 1\n",
    "                else:\n",
    "                    count_dict[splitted[i]] = 1\n",
    "            else:\n",
    "                continue\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two dataframes for hs labels and sa labels \n",
    "\n",
    "def create_table(train, test, binary=True):\n",
    "    if binary:\n",
    "        hs_df = pd.DataFrame({\"Offensiveness\": list(count_hs_labels(test).keys()), \"Test\":list(count_hs_labels(test).values()), \"Train\": list(count_hs_labels(train).values())})\n",
    "        sa_df = pd.DataFrame({\"Speech Acts\": list(count_sa_labels(test).keys()), \"Test\":list(count_sa_labels(test).values()), \"Train\": list(count_sa_labels(train).values())}) \n",
    "    else:\n",
    "        hs_df = pd.DataFrame({\"Offensiveness\": list(count_hs_labels(test, binary=False).keys()), \"Test\":list(count_hs_labels(test, binary=False).values()), \"Train\": list(count_hs_labels(train, binary=False).values())})\n",
    "        sa_df = pd.DataFrame({\"Speech Acts\": list(count_sa_labels(test).keys()), \"Test\":list(count_sa_labels(test).values()), \"Train\": list(count_sa_labels(train).values())}) \n",
    "    return hs_df, sa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "Offensiveness &  Test &  Train \\\\\n",
      "\\midrule\n",
      "        abuse &    20 &     80 \\\\\n",
      "     explicit &    20 &     80 \\\\\n",
      "     implicit &    20 &     80 \\\\\n",
      "       insult &    20 &     80 \\\\\n",
      "        other &    20 &     80 \\\\\n",
      "    profanity &    20 &     80 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "Speech Acts &  Test &  Train \\\\\n",
      "\\midrule\n",
      "  DIRECTIVE &   123 &    507 \\\\\n",
      "     UNSURE &    17 &    133 \\\\\n",
      " EXPRESSIVE &    82 &     71 \\\\\n",
      "  ASSERTIVE &   144 &    520 \\\\\n",
      "     COMOTH &    17 &    310 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/4yx64stx14x98pvlwz2br_nr0000gn/T/ipykernel_50629/2846528080.py:2: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(hs_df.to_latex(index=False))\n",
      "/var/folders/7k/4yx64stx14x98pvlwz2br_nr0000gn/T/ipykernel_50629/2846528080.py:3: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(sa_df.to_latex(index=False))\n"
     ]
    }
   ],
   "source": [
    "hs_df, sa_df = create_table(train, test, binary=False)\n",
    "print(hs_df.to_latex(index=False))\n",
    "print(sa_df.to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-nightly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
